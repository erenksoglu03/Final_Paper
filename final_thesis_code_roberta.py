# -*- coding: utf-8 -*-
"""Final_Thesis_Code_ROBERTA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bdWm-pf_ZQniYbPsptraOI5FStkWZvvy
"""

#IMPORTING LIBRARIES
import pandas as pd
import numpy as np
from datetime import datetime, date
import matplotlib.pyplot as plt
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from scipy.special import softmax

df = pd.read_csv("all_companies_tweets.csv")

df.shape

"""FILTERING 6 STOCKS BY THE NUMBER OF LIKES AND RETWEETS"""

apple_filter = (df['apple'] == True)
condition = (df['retweet_num'] >= 30) | (df['like_num'] >= 50)
apple_reduced = df.loc[apple_filter & condition].reset_index()
apple_reduced.shape

amazon_filter = (df['amazon'] == True)
condition = (df['retweet_num'] >= 30) | (df['like_num'] >= 50)
amazon_reduced = df.loc[amazon_filter & condition].reset_index()
amazon_reduced.shape

tesla_filter = (df['tesla'] == True)
condition = (df['retweet_num'] >= 100) | (df['like_num'] >= 200)
tesla_reduced = df.loc[tesla_filter & condition].reset_index()
tesla_reduced.shape

microsoft_filter = (df['microsoft'] == True)
condition = (df['retweet_num'] >= 30) | (df['like_num'] >= 50)
microsoft_reduced = df.loc[microsoft_filter & condition].reset_index()
microsoft_reduced.shape

google_filter = (df['google'] == True)
condition = (df['retweet_num'] >= 30) | (df['like_num'] >= 50)
google_reduced = df.loc[google_filter & condition].reset_index()
google_reduced.shape

netflix = np.zeros(df.shape[0],dtype=bool)
for i in range(df.shape[0]):
  if "netflix" in df.text[i].lower():
    netflix[i] = True
df["netflix"] = netflix
netflix_filter = (df['netflix'] == True)
condition = (df['retweet_num'] >= 5) | (df['like_num'] >= 5)
netflix_reduced = df.loc[netflix_filter & condition]
netflix_reduced.shape

"""LOADING ROBERTA MODEL

"""

# Loading the pre-trained model and tokenizer
MODEL = "cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

# Function to classify tweets in batches
def classify_tweets_in_batches(tweet_list, batch_size=10):
    num_tweets = len(tweet_list)
    for i in range(0, num_tweets, batch_size):
        batch_tweets = list(tweet_list[i:i+batch_size])
        encoded_inputs = tokenizer(batch_tweets, return_tensors='pt', padding=True, truncation=True)
        outputs = model(**encoded_inputs)
        scores = outputs.logits
        probabilities = softmax(scores.detach().numpy(), axis=1)
        predicted_labels = np.argmax(probabilities, axis=1)
        sentiment_labels = [model.config.id2label[label_id] for label_id in predicted_labels]
        for label in sentiment_labels:
            yield label #yiled is used instead of return due to RAM memory considerations

"""APPLYING ROBERTA MODEL AND SAVING THE SENTIMENT LABELED DATAFRAME SEPARATELY FOR EACH STOCK

ROBERTA FOR NETFLIX
"""

tweets = netflix_reduced.text.values
sentiment_labels = list(classify_tweets_in_batches(tweets))
netflix_reduced["sentiment"] = sentiment_labels
netflix_reduced.to_csv("netflix_reduced_sentiment.csv",index=False)

"""ROBERTA FOR AMAZON"""

tweets = amazon_reduced.text.values
sentiment_labels = list(classify_tweets_in_batches(tweets))
amazon_reduced["sentiment"] = sentiment_labels
amazon_reduced.to_csv("amazon_reduced_sentiment.csv",index=False)

"""ROBERTA FOR APPLE"""

tweets = apple_reduced.text.values
sentiment_labels = list(classify_tweets_in_batches(tweets))
apple_reduced["sentiment"] = sentiment_labels
apple_reduced.to_csv("apple_reduced_sentiment.csv",index=False)

"""ROBERTA FOR MICROSOFT"""

tweets = microsoft_reduced.text.values
sentiment_labels = list(classify_tweets_in_batches(tweets))
microsoft_reduced["sentiment"] = sentiment_labels
microsoft_reduced.to_csv("microsoft_reduced_sentiment.csv",index=False)

"""ROBERTA FOR GOOGLE"""

tweets = google_reduced.text.values
sentiment_labels = list(classify_tweets_in_batches(tweets))
google_reduced["sentiment"] = sentiment_labels
google_reduced.to_csv("google_reduced_sentiment.csv",index=False)

"""ROBERTA FOR TESLA"""

tweets = tesla_reduced.text.values
sentiment_labels = list(classify_tweets_in_batches(tweets))
tesla_reduced["sentiment"] = sentiment_labels
tesla_reduced.to_csv("tesla_reduced_sentiment.csv",index=False)

